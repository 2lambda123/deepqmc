{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H2+     Energy = -0.6023424   for R = 1.9972\n",
    "#fit(batch_size=10000, n_el=1, steps=500, epochs=1, RR=[[-1, 0, 0], [1., 0, 0]])\n",
    "\n",
    "#H2\t\t Energy = -1.173427    for R = 1.40\n",
    "#fit(batch_size=10000,n_el=2,steps=100,epochs=5,RR=torch.tensor([[-0.7,0,0],[0.7,0,0]]))\n",
    "\n",
    "#He+\t Energy = -1.9998\n",
    "#fit(batch_size=10000,n_el=1,steps=100,epochs=5,RR=torch.tensor([[0.,0,0]]),RR_charges=[2])\n",
    "\n",
    "#He\t\t Energy = âˆ’2.90338583\n",
    "#fit(batch_size=10000,n_el=2,steps=300,epochs=5,RR=torch.tensor([[0.3,0,0]]),RR_charges=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport  dlqmc.sampling, dlqmc.utils, dlqmc.nn.base, dlqmc.fit\n",
    "%config InlineBackend.figure_format = 'svg' \n",
    "%config InlineBackend.print_figure_kwargs = \\\n",
    "    {'bbox_inches': 'tight', 'dpi': 300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from scipy import special\n",
    "import scipy.stats as sps\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "#from torch.utils.data import DataLoader, RandomSampler\n",
    "#from torch.distributions import Normal\n",
    "from pyscf import gto, scf, dft\n",
    "import pyscf\n",
    "from pyscf.data.nist import BOHR\n",
    "import time\n",
    "from functools import partial\n",
    "from tqdm.auto import tqdm, trange\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from dlqmc.nn.base import * \n",
    "from dlqmc.geom import *\n",
    "from dlqmc.nn.gto import *\n",
    "from dlqmc.nn import *\n",
    "from dlqmc.sampling import langevin_monte_carlo, hmc ,samples_from\n",
    "from dlqmc.fit import *\n",
    "from dlqmc.nn.anti import *\n",
    "#from dlqmc.utils import assign_where\n",
    "from dlqmc.physics import (\n",
    "    local_energy, grad, quantum_force,nuclear_potential,\n",
    "    nuclear_energy, laplacian, electronic_potential\n",
    ")\n",
    "#from dlqmc.analysis import autocorr_coeff, blocking\n",
    "from dlqmc.nn import ssp\n",
    "from dlqmc.nn.hannet import HanNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2p = geomdb['H2+']\n",
    "h2 = geomdb['H2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normplot(x,y,norm,*args,**kwargs):\n",
    "    if norm:\n",
    "        plt.plot(x,y/np.max(np.abs(y)),*args,**kwargs)\n",
    "    else:\n",
    "        plt.plot(x,y,*args,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_pair(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.NN1=nn.Sequential(\n",
    "            torch.nn.Linear(6, 10),\n",
    "            SSP(),\n",
    "            #torch.nn.Linear(10, 10),\n",
    "            #SSP(),\n",
    "            torch.nn.Linear(10, 10)\n",
    "            )\n",
    "        \n",
    "    def forward(self,x1,x2):\n",
    "        d=torch.cat((x1,x2),dim=-1)\n",
    "        return self.NN1(d)\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.NN1=nn.Sequential(\n",
    "            torch.nn.Linear(10, 10),\n",
    "            SSP(),\n",
    "            #torch.nn.Linear(15, 10),\n",
    "            #SSP(),\n",
    "            torch.nn.Linear(10, 1))#,\n",
    "            #nn.Sigmoid())\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return torch.sigmoid(self.NN1(x).flatten())\n",
    "\n",
    "    \n",
    "class WFNetAnti(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        geom,\n",
    "        n_electrons,\n",
    "        net,\n",
    "        net_pair,\n",
    "        ion_pot=0.5,\n",
    "        cutoff=10.0,\n",
    "        n_dist_feats=32,\n",
    "        alpha=1.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dist_basis = DistanceBasis(n_dist_feats)\n",
    "        self.register_buffer('coords', geom.coords)\n",
    "        self.register_buffer('charges', geom.charges)\n",
    "        self.nuc_asymp = NuclearAsymptotic(self.charges, ion_pot, alpha=alpha)\n",
    "        #self.el_cusp = ElectronicCusp()\n",
    "        n_atoms = len(geom.charges)\n",
    "        n_pairs = n_electrons * n_atoms + n_electrons * (n_electrons - 1) // 2\n",
    "        self.deep_lin = nn.Sequential(\n",
    "            nn.Linear(n_pairs * n_dist_feats, 64),\n",
    "            SSP(),\n",
    "            nn.Linear(64, 64),\n",
    "            SSP(),\n",
    "            nn.Linear(64, 64),\n",
    "            SSP(),\n",
    "            nn.Linear(64, 64),\n",
    "            SSP(),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "        self.antisym = AntisymmetricPart(net, net_pair)\n",
    "        self._pdist = PairwiseDistance3D()\n",
    "        self._psdist = PairwiseSelfDistance3D()\n",
    "\n",
    "    def _featurize(self, rs):\n",
    "        dists_nuc = self._pdist(rs, self.coords[None, ...])\n",
    "        dists_el = self._psdist(rs)\n",
    "        dists = torch.cat([dists_nuc.flatten(start_dim=1), dists_el], dim=1)\n",
    "        xs = self.dist_basis(dists)  # .flatten(start_dim=1)\n",
    "        return xs.flatten(start_dim=1), (dists_nuc, dists_el)\n",
    "\n",
    "    def forward(self, rs):\n",
    "        #dists_nuc = self._pdist(rs, self.geom.coords[None, ...])\n",
    "        xs, (dists_nuc, dists_el) = self._featurize(rs)\n",
    "        ys = self.deep_lin(xs).squeeze(dim=1)\n",
    "        return self.nuc_asymp(dists_nuc) * torch.exp(ys) * self.antisym(rs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HF WF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = gto.M(\n",
    "    atom=[\n",
    "        ['H', (0, 0, 0)],\n",
    "        ['H', (1.484, 0, 0)]\n",
    "    ],\n",
    "    unit='bohr',\n",
    "    basis='4-31G',\n",
    "    charge=0,\n",
    "    spin=2,\n",
    ")\n",
    "mf = scf.RHF(mol)\n",
    "mf.kernel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gtowf.get_aos(torch.randn(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtowf = TorchGTOSlaterWF(mf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_electrons=2\n",
    "molecule = h2\n",
    "\n",
    "Onet = Net().cuda()\n",
    "Pnet = Net_pair().cuda()\n",
    "net = WFNetAnti(molecule,n_electrons,Onet,Pnet,ion_pot=0.7).cuda()\n",
    "\n",
    "L = []\n",
    "V = []\n",
    "\n",
    "x_line = torch.cat((torch.linspace(-3, 3, 500)[:, None], torch.zeros((500, 3*n_electrons-1))), dim=1)\n",
    "x_line=x_line.view(-1,n_electrons,3).cuda()\n",
    "#mesh = get_3d_cube_mesh([(-6, 6), (-4, 4), (-4, 4)], [600, 400, 400])\n",
    "\n",
    "opt = torch.optim.Adam(net.parameters(), lr=1e-2)\n",
    "t_start=time.time()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=1, gamma=0.999)\n",
    "\n",
    "steps = 200\n",
    "batchsize = 50_000\n",
    "n_resamplings = 100\n",
    "n_walker = 1_000\n",
    "\n",
    "sampler = langevin_monte_carlo(\n",
    "    gtowf,\n",
    "    torch.randn(n_walker, n_electrons, 3, device='cuda'),\n",
    "    tau=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "#temporary\n",
    "molecule._coords=molecule._coords.cuda()\n",
    "molecule._charges=molecule._charges.cuda()\n",
    "\n",
    "for i_step in range(steps):\n",
    "        \n",
    "    if i_step%(steps//4) == 0 or i_step==steps:\n",
    "        with torch.no_grad():\n",
    "            Psi2 = net(x_line)**2\n",
    "            plt.plot(x_line[:,0 , 0].cpu().detach().numpy(), Psi2.cpu().detach().numpy(),label=i_step)\n",
    "    \n",
    "    scheduler.step()\n",
    "    if i_step%(steps//n_resamplings)==0:\n",
    "        print(\"resample                                                                        \",end=\"\\r\")\n",
    "        rs,rs_psis  = samples_from(sampler,range(int(batchsize*steps/(n_resamplings*n_walker))))[0:-1]\n",
    "        rs = rs.flatten(end_dim=1).cuda()\n",
    "        rs_psis = rs_psis.flatten(end_dim=1).cuda()\n",
    "        idx = torch.randperm(len(rs))\n",
    "        rs = rs[idx]\n",
    "        rs_psis = rs_psis[idx]\n",
    "        \n",
    "    r=rs[i_step%(steps//n_resamplings)*batchsize:(i_step%(steps//n_resamplings)+1)*batchsize]\n",
    "    loss = torch.sum((net(r)**2-gtowf(r).cuda()**2)**2)\n",
    "    \n",
    "    print(\"Progress {:2.0%}\".format(i_step /steps)+\"   ->\"+\"I\"*(int(i_step/steps*100)//10)+\"i\"*(int(i_step/steps*100)%10)+\"  \"+\"current loss = \"+str(np.round(loss.item(),4))+\"        \", end=\"\\r\")\n",
    "\n",
    "\n",
    "    loss.backward()\n",
    "    L.append(loss.cpu().detach().numpy())\n",
    "    #V.append(((E_loc**2-E_loc.mean()**2).mean()).cpu().detach().numpy())\n",
    "        \n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "plt.legend()\n",
    "print(\"it took =\"+str(np.round(time.time()-t_start,5))+\"                    \")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_line = torch.cat((torch.linspace(-5, 5, 5000)[:, None], torch.zeros((5000, 3*n_electrons-1))), dim=1)\n",
    "x_line[:,3] = 1.484/2\n",
    "x_line=x_line.view(-1,n_electrons,3).cuda()\n",
    "x_line.requires_grad = True\n",
    "net.cuda()\n",
    "f_line = net._featurize(x_line)\n",
    "normed=True\n",
    "#normplot(x_line[:,0 , 0].cpu().detach().numpy(), torch.exp(net.deep_lin(f_line[0])).squeeze().cpu().detach().numpy(),label=\"sym\",norm=normed)\n",
    "#normplot(x_line[:,0 , 0].cpu().detach().numpy(), net.antisym(x_line).cpu().detach().numpy(),label=\"anti\",norm=normed)\n",
    "#normplot(x_line[:,0 , 0].cpu().detach().numpy(), net.nuc_asymp(f_line[1][0]).cpu().detach().numpy(),label=\"asym\",norm=normed)\n",
    "#N = net.nuc_asymp(f_line[1][0]).cpu().detach().numpy()\n",
    "#normplot(x_line[:,0,0].cpu().detach().numpy(),-1*(N*x_line[:,0,0].cpu().detach().numpy()),label=\"asym*line\",norm=normed)\n",
    "normplot(x_line[:,0 , 0].cpu().detach().numpy(), net(x_line).cpu().detach().numpy()**2,label=\"WF\",norm=normed,lw=2,color='k')\n",
    "normplot(x_line[:,0 , 0].cpu().detach().numpy(), gtowf(x_line.cpu().detach()).numpy()**2,label=\"gtowf\",norm=normed,lw=2,color='grey')\n",
    "\n",
    "plt.axhline(0,ls=':',color='k')\n",
    "plt.axvline(0,ls=':',color='k')\n",
    "\n",
    "#plt.ylim(-1,2)\n",
    "x_line.requires_grad = False\n",
    "plt.legend()\n",
    "#plt.savefig('lastrunwf.png')\n",
    "plt.show()\n",
    "plt.subplot2grid((2,1),(0,0))\n",
    "plt.plot(L[:steps//10])\n",
    "plt.yscale('log')\n",
    "plt.subplot2grid((2,1),(1,0))\n",
    "plt.plot(L[steps//10:])\n",
    "plt.yscale('log')\n",
    "#plt.savefig('lastrunloss.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "for i in range(6):\n",
    "    plt.subplot2grid((2,3),(i//3,i%3))\n",
    "    x = torch.zeros(500, 6)\n",
    "    x[:,0] = 0\n",
    "    x[:,i] = torch.linspace(-5, 5, 500)\n",
    "    x = x.view(-1,2,3)\n",
    "    plt.title(\"electron \" +str(i//3+1))\n",
    "    plt.plot(np.linspace(-5, 5, 500),gtowf(x).detach().numpy()**2)\n",
    "    plt.plot(np.linspace(-5, 5, 500),net(x).cpu().detach().numpy()**2)\n",
    "    plt.axhline(0,ls=':',color='k')\n",
    "    plt.savefig(\"supervised.png\")\n",
    "    #plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### try:\n",
    "    net.cuda()\n",
    "    plt.figure(figsize=(12,4))\n",
    "    for i in range(6):\n",
    "        plt.subplot2grid((2,3),(i//3,i%3))\n",
    "        x = torch.zeros(500, 6)\n",
    "        x[:,i] = torch.linspace(-5, 5, 500)\n",
    "        x = x.view(-1,2,3)\n",
    "        plt.title(\"electron \" +str(i//3+1))\n",
    "        plt.plot(np.linspace(-5, 5, 500),net(x.cuda()).cpu().detach().numpy()**2)\n",
    "        plt.axhline(0,ls=':',color='k')\n",
    "        #plt.axis('off')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    G = np.array(np.meshgrid(np.linspace(-5, 5, 500),np.linspace(-5, 5, 500))).T.reshape(-1,2)\n",
    "    F = np.append(G,np.ones((250000,4)),axis=-1)\n",
    "    H = np.append(F[:,[0,2,4]],F[:,[1,3,5]],axis=-1)\n",
    "    W1 = gtowf(torch.from_numpy(H).view(-1,2,3)).view(500,500).numpy()\n",
    "    W2 = net(torch.from_numpy(H).view(-1,2,3).type(torch.FloatTensor).cuda()).view(500,500).cpu().detach().numpy()\n",
    "    levels=30\n",
    "    plt.figure(figsize=(8,3))\n",
    "    plt.subplot2grid((1,2),(0,0))\n",
    "    plt.title(\"gtowf\")\n",
    "    plt.contourf(W1,levels)\n",
    "    plt.colorbar()\n",
    "    plt.subplot2grid((1,2),(0,1))\n",
    "    plt.title(\"netwf\")\n",
    "    plt.contourf(W2,levels)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_electrons=2\n",
    "n_up = 2\n",
    "n_down = n_electrons-n_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = HanNet(h2,n_up,n_down).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    sampler = hmc(\n",
    "        net,\n",
    "        torch.randn(1000, n_electrons, 3, device='cuda'),\n",
    "        dysteps=3,\n",
    "        stepsize=0.2,\n",
    "        tau = 0.1,\n",
    "        cutoff = 1.0\n",
    "    )\n",
    "else:\n",
    "    sampler = langevin_monte_carlo(\n",
    "        gtowf,\n",
    "        torch.randn(1000, n_electrons, 3, device='cuda'),\n",
    "        tau=0.1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t=time.time()\n",
    "#samples = samples_from(sampler,range(1000))[0].flatten(end_dim=1)\n",
    "#print(\"it took: \"+str(time.time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecule = h2\n",
    "fit_wfnet(\n",
    "    net,\n",
    "    partial(loss_local_energy, E_ref=-1.1,p=2),\n",
    "    torch.optim.Adam(net.parameters(), lr=1e-3),\n",
    "    wfnet_fit_driver(\n",
    "            sampler,\n",
    "            samplings=range(1),\n",
    "            n_epochs=1,\n",
    "            n_sampling_steps=100,\n",
    "            batch_size=1_000,\n",
    "            n_discard=50,\n",
    "            range_sampling=partial(trange, desc='sampling steps', leave=False),\n",
    "            range_training=partial(trange, desc='training steps', leave=False),\n",
    "        ),\n",
    "    clip_grad = None,\n",
    "    exclude_below = 0,\n",
    "    writer = SummaryWriter(f'runs/'),\n",
    "    )\n",
    "\n",
    "fit_wfnet(\n",
    "    net2,\n",
    "    partial(loss_local_energy, E_ref=None,p=1),\n",
    "    torch.optim.Adam(net.parameters(), lr=1e-3),\n",
    "    wfnet_fit_driver(\n",
    "            sampler,\n",
    "            samplings=range(1),\n",
    "            n_epochs=1,\n",
    "            n_sampling_steps=1000,\n",
    "            batch_size=1_000,\n",
    "            n_discard=50,\n",
    "            range_sampling=partial(trange, desc='sampling steps', leave=False),\n",
    "            range_training=partial(trange, desc='training steps', leave=False),\n",
    "        ),\n",
    "    clip_grad = None,\n",
    "    writer = SummaryWriter(f'runs/'),\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_line = torch.cat((torch.linspace(-5, 5, 5000)[:, None], torch.zeros((5000, 3*n_electrons-1))), dim=1)\n",
    "x_line[:,3]=h2.coords[1][0]/2\n",
    "x_line=x_line.view(-1,n_electrons,3)#.cuda()\n",
    "x_line.requires_grad = True\n",
    "gtowf\n",
    "\n",
    "normed=True\n",
    "#normplot(x_line[:,0 , 0].cpu().detach().numpy(), torch.exp(net.deep_lin(f_line[0])).squeeze().cpu().detach().numpy(),label=\"sym\",norm=normed)\n",
    "#normplot(x_line[:,0 , 0].cpu().detach().numpy(), net.antisym(x_line).cpu().detach().numpy(),label=\"anti\",norm=normed)\n",
    "#normplot(x_line[:,0 , 0].cpu().detach().numpy(), net.nuc_asymp(f_line[1][0]).cpu().detach().numpy(),label=\"asym\",norm=normed)\n",
    "#N = net.nuc_asymp(f_line[1][0]).cpu().detach().numpy()\n",
    "#normplot(x_line[:,0,0].cpu().detach().numpy(),-1*(N*x_line[:,0,0].cpu().detach().numpy()),label=\"asym*line\",norm=normed)\n",
    "#d=net(x_line).cpu().detach().numpy()\n",
    "#D.append(d)\n",
    "normplot(x_line[:,0 , 0].cpu().detach().numpy(), gtowf(x_line).cpu().detach().numpy(),label=\"WF\",norm=normed,lw=2,color='k')\n",
    "\n",
    "plt.axhline(0,ls=':',color='k')\n",
    "plt.axvline(0,ls=':',color='k')\n",
    "\n",
    "#plt.ylim(-1,2)\n",
    "x_line.requires_grad = False\n",
    "plt.legend()\n",
    "#plt.savefig('lastrunwf.png')\n",
    "plt.show()\n",
    "#plt.subplot2grid((2,1),(0,0))\n",
    "#plt.plot(L[:steps//10])\n",
    "#plt.yscale('log')\n",
    "#plt.subplot2grid((2,1),(1,0))\n",
    "#plt.plot(L[steps//10:])\n",
    "#plt.yscale('log')\n",
    "#plt.savefig('lastrunloss.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(x_line[:,0 , 0].cpu().detach().numpy(),net.antisym.net_pair_anti(x_line[:,0],x_line[:,1]).cpu().detach().numpy())\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp = net.antisym.net_pair_anti(torch.from_numpy(H[:,0:3]).type(torch.FloatTensor).cuda(),torch.from_numpy(H[:,3:]).type(torch.FloatTensor).cuda()).cpu().detach().numpy()[:,9].reshape(500,500)\n",
    "#plt.contourf(tmp)\n",
    "#plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=time.time()\n",
    "samples = samples_from(sampler,range(100))[0].flatten(end_dim=1)\n",
    "print(\"it took: \"+str(time.time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(\n",
    "    samples[:,0, 0].cpu().detach().numpy(),\n",
    "    samples[:,0, 1].cpu().detach().numpy(),\n",
    "    bins=100,\n",
    "    range=[[-3, 3+h2.coords[1,0].cpu().numpy()], [-3, 3]],\n",
    ")                                   \n",
    "plt.gca().set_aspect(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = net.cpu()\n",
    "#samples = samples.cpu()\n",
    "h2._coords  = h2._coords.cuda()\n",
    "h2._charges = h2._charges.cuda()\n",
    "h2.coords.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_loc = dlqmc.utils.batch_eval_tuple(partial(local_energy, wf=lambda x: net(x),geom=h2),tqdm(samples.view([-1,n_electrons,3]).split(1000)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.where((E_loc.detach().numpy())>100)[0].shape)\n",
    "#print(np.where((E_loc.detach().numpy())<-100)[0].shape)\n",
    "#print(np.min(E_loc.detach().numpy()))\n",
    "#print(np.max(E_loc.detach().numpy()))\n",
    "#net(samples[np.where((E_loc.detach().numpy())>10)])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=E_loc.clamp(-10, 10).mean().item()\n",
    "\n",
    "h = plt.hist(E_loc.detach().clamp(-1.5, 1).cpu().numpy(), bins=100,alpha = 0.5,color='b')\n",
    "plt.annotate(\"mean = \"+str(np.round(mean,4)),(-0.3,np.max(h[0])/2),color='b')\n",
    "plt.annotate(\"var     = \"+str(np.round(np.var(E_loc.detach().clamp(-10, 10).cpu().numpy()),4)),(-0.3,np.max(h[0])/2-np.max(h[0])/15),color='b')\n",
    "\n",
    "#mean=e_loc_net.mean()\n",
    "\n",
    "#h = plt.hist(e_loc_net, bins=100,color='r',alpha = 0.5)\n",
    "#plt.annotate(\"mean = \"+str(np.round(mean,4)),(0,np.max(h[0])/2-3000),color='r')\n",
    "#plt.annotate(\"var     = \"+str(np.round(np.var(e_loc_net),4)),(0,np.max(h[0])/2-np.max(h[0])/15-3000),color='r')\n",
    "plt.savefig('lastruneloc.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e_loc_net=E_loc.detach().clamp(-1.5, 1).cpu().numpy().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_allocated())\n",
    "print(torch.cuda.memory_cached(device=None))\n",
    "print(torch.cuda.max_memory_cached(device=None))\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $H_{10}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=1.5#1.786\n",
    "n=2\n",
    "hn = Geometry([[d*i, 0., 0.] for i in range(n)], [1. for i in range (n)])\n",
    "print(hn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = gto.M(\n",
    "    atom=[\n",
    "        ['H', (d*i, 0, 0)] for i in range(n)      \n",
    "    ],\n",
    "    unit='bohr',\n",
    "    basis='6-31G',#'aug-cc-pV5Z',\n",
    "    charge=0,\n",
    "    spin=0,\n",
    ")\n",
    "mf = scf.RHF(mol)\n",
    "mf.kernel()\n",
    "gtowf = TorchGTOSlaterWF(mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_electrons=n\n",
    "n_up = n//2\n",
    "n_down = n_electrons-n_up\n",
    "net = HanNet(hn,n_up,n_down, \n",
    "        basis_dim=8,\n",
    "        kernel_dim=16,\n",
    "        embedding_dim=32,\n",
    "        latent_dim=5,\n",
    "        n_interactions=2,\n",
    "        n_orbital_layers=3,).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    sampler = hmc(\n",
    "        net,\n",
    "        torch.randn(1000, n_electrons, 3, device='cuda'),\n",
    "        dysteps=3,\n",
    "        stepsize=0.2,\n",
    "        tau = 0.1,\n",
    "        cutoff = 1.0\n",
    "    )\n",
    "else:\n",
    "    sampler = langevin_monte_carlo(\n",
    "        net,\n",
    "        torch.randn(1000, n_electrons, 3, device='cuda'),\n",
    "        tau=0.1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecule = hn\n",
    "fit_wfnet(\n",
    "    net,\n",
    "    partial(loss_local_energy, E_ref=-1.1,p=2),\n",
    "    torch.optim.Adam(net.parameters(), lr=1e-3),\n",
    "    wfnet_fit_driver(\n",
    "            sampler,\n",
    "            samplings=range(1),\n",
    "            n_epochs=1,\n",
    "            n_sampling_steps=60,\n",
    "            batch_size=1_000,\n",
    "            n_discard=50,\n",
    "            range_sampling=partial(trange, desc='sampling steps', leave=False),\n",
    "            range_training=partial(trange, desc='training steps', leave=False),\n",
    "        ),\n",
    "    clip_grad = None,\n",
    "    writer = SummaryWriter(f'runs/'),\n",
    "    )\n",
    "\n",
    "fit_wfnet(\n",
    "    net,\n",
    "    partial(loss_local_energy, E_ref=None,p=1),\n",
    "    torch.optim.Adam(net.parameters(), lr=1e-3),\n",
    "    wfnet_fit_driver(\n",
    "            sampler,\n",
    "            samplings=range(1),\n",
    "            n_epochs=1,\n",
    "            n_sampling_steps=60,\n",
    "            batch_size=1_000,\n",
    "            n_discard=50,\n",
    "            range_sampling=partial(trange, desc='sampling steps', leave=False),\n",
    "            range_training=partial(trange, desc='training steps', leave=False),\n",
    "        ),\n",
    "    clip_grad = None,\n",
    "    writer = SummaryWriter(f'runs/'),\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_line = torch.cat((torch.linspace(-1, 16, 500)[:, None], torch.zeros((500, 3*n_electrons-1))), dim=1)\n",
    "for i in range(n_electrons-1):\n",
    "    x_line[:,3*(i+1)]=0.7*(i+1)\n",
    "x_line=x_line.view(-1,n_electrons,3).cuda()\n",
    "print(x_line.shape)\n",
    "x_line.requires_grad = True\n",
    "net.cuda()\n",
    "\n",
    "normed=True\n",
    "#normplot(x_line[:,0 , 0].cpu().detach().numpy(), net(x_line).cpu().detach().numpy(),label=\"WF\",norm=normed,lw=2,color='k')\n",
    "normplot(x_line[:,0 , 0].cpu().detach().numpy(), gtowf(x_line).cpu().detach().numpy(),label=\"WF\",norm=normed,lw=2,color='k')\n",
    "\n",
    "plt.axhline(0,ls=':',color='k')\n",
    "for i in range(n):\n",
    "    plt.axvline(d*i,ls=':',color='k')\n",
    "\n",
    "#plt.ylim(-1,2)\n",
    "x_line.requires_grad = False\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = gto.M(\n",
    "    atom=[\n",
    "        ['B', (0, 0, 0)]\n",
    "    ],\n",
    "    unit='bohr',\n",
    "    basis='4-31G',\n",
    "    cart=True,\n",
    "    charge=0,\n",
    "    spin=1,\n",
    ")\n",
    "mf = scf.RHF(mol)\n",
    "mf.kernel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bohr=geomdb['H']\n",
    "bohr._coords=torch.tensor([[0,0,0.]])\n",
    "bohr._charges=torch.tensor([5.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = gto.M(\n",
    "    atom=[\n",
    "        ['H', (0, 0, 0)],\n",
    "        ['H', (1.484, 0, 0)]\n",
    "    ],\n",
    "    unit='bohr',\n",
    "    basis='4-31G',\n",
    "    cart=True,\n",
    "    charge=0,\n",
    "    spin=2,\n",
    ")\n",
    "mf = scf.RHF(mol)\n",
    "mf.kernel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlqmc.utils import nondiag\n",
    "\n",
    "class Backflow(nn.Module):\n",
    "      \n",
    "    def __init__(\n",
    "        self,\n",
    "        n_up,\n",
    "        n_down,\n",
    "        n_interactions,\n",
    "        basis_dim\n",
    "    ):\n",
    "            \n",
    "        super().__init__()\n",
    "        def interaction_factory(basis_dim):\n",
    "                modules = {\n",
    "                    'interact': get_log_dnn(basis_dim, 1, SSP, n_layers=4, last_bias=False),\n",
    "                }\n",
    "                return nn.ModuleDict(modules)\n",
    "            \n",
    "        self.interactions = nn.ModuleList(\n",
    "            [\n",
    "                interaction_factory(basis_dim)\n",
    "                for _ in range(n_interactions)\n",
    "            ])\n",
    "        \n",
    "        self.dist_basis = DistanceBasis(basis_dim)\n",
    "            \n",
    "    def forward(self,rs, debug=NULL_DEBUG):\n",
    "        xs = rs.clone()\n",
    "        for i, interaction in enumerate(self.interactions):\n",
    "            dists_basis = self.dist_basis(pairwise_distance(xs,xs))\n",
    "            *batch_dims, n_elec, n_elec, basis_dim = dists_basis.shape\n",
    "            c_i, c_j, c_shape = self._conv_indexing(n_elec, n_elec, batch_dims)\n",
    "            dists_basis = dists_basis[..., c_i, c_j, :]\n",
    "            Ws = interaction.interact(dists_basis)\n",
    "            zs = (Ws.view(*c_shape) * (xs[:, c_j].view(*c_shape)-xs[:,:,None,:])).sum(dim=2)\n",
    "            xs = xs + zs\n",
    "        return xs\n",
    "    \n",
    "    @staticmethod\n",
    "    def _conv_indexing(n_elec, n_all, batch_dims):\n",
    "        i, j = np.mask_indices(n_all, nondiag)\n",
    "        n = n_elec * (n_all - 1)\n",
    "        i, j = i[:n], j[:n]\n",
    "        shape = (*batch_dims, n_elec, n_all - 1, -1)\n",
    "        return i, j, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from dlqmc.geom import Geometry\n",
    "from dlqmc.utils import NULL_DEBUG\n",
    "from dlqmc.nn.anti import eval_slater\n",
    "from dlqmc.nn.base import BaseWFNet\n",
    "from dlqmc.nn.base import DistanceBasis\n",
    "from dlqmc.nn.gto import GTOBasis\n",
    "\n",
    "\n",
    "class HFNet(BaseWFNet):\n",
    "    def __init__(self, geom, n_up, n_down, basis, n_interactions):\n",
    "        super().__init__()\n",
    "        self.n_up, self.n_down = n_up, n_down\n",
    "        self.register_geom(geom)\n",
    "        self.basis = basis\n",
    "        self.mo = nn.Linear(basis.dim, max(n_up, n_down), bias=False)\n",
    "        self.backflow = Backflow(n_up, n_down,n_interactions,20)\n",
    "\n",
    "    def init_from_pyscf(self, mf):\n",
    "        mo_coeff = mf.mo_coeff.copy()\n",
    "        if mf.mol.cart:\n",
    "            mo_coeff *= np.sqrt(np.diag(mf.mol.intor('int1e_ovlp_cart')))[:, None]\n",
    "        self.mo.weight.detach().copy_(\n",
    "            torch.from_numpy(mo_coeff[:, : max(self.n_up, self.n_down)].T)\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_pyscf(cls, mf, n_interactions):\n",
    "        n_up = (mf.mo_occ >= 1).sum()\n",
    "        n_down = (mf.mo_occ == 2).sum()\n",
    "        assert (mf.mo_occ[:n_down] == 2).all()\n",
    "        assert (mf.mo_occ[n_down:n_up] == 1).all()\n",
    "        assert (mf.mo_occ[n_up:] == 0).all()\n",
    "        geom = Geometry(mf.mol.atom_coords().astype('float32'), mf.mol.atom_charges())\n",
    "        basis = GTOBasis.from_pyscf(mf.mol)\n",
    "        wf = cls(geom, n_up, n_down, basis, n_interactions)\n",
    "        wf.init_from_pyscf(mf)\n",
    "        return wf\n",
    "\n",
    "    def __call__(self, rs, debug=NULL_DEBUG):\n",
    "        batch_dim, n_elec = rs.shape[:2]\n",
    "        rs_back = self.backflow(rs)\n",
    "        xs = debug['aos'] = self.basis(rs_back.flatten(end_dim=1)).view(\n",
    "            batch_dim, n_elec, -1\n",
    "        )\n",
    "        xs = debug['slaters'] = self.mo(xs)\n",
    "        det_up = debug['det_up'] = eval_slater(xs[:, : self.n_up, : self.n_up])\n",
    "        det_down = debug['det_down'] = eval_slater(xs[:, self.n_up :, : self.n_down])\n",
    "        return det_up * det_down\n",
    "\n",
    "    def orbitals(self, rs):\n",
    "        return self.mo(self.basis(rs))\n",
    "\n",
    "    def density(self, rs):\n",
    "        xs = self.orbitals(rs)\n",
    "        return sum(\n",
    "            (xs[:, :n_elec] ** 2).sum(dim=-1) for n_elec in (self.n_up, self.n_down)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_electrons=2\n",
    "n_up = 2\n",
    "n_down = n_electrons-n_up\n",
    "molecule = h2\n",
    "\n",
    "net0=HFNet.from_pyscf(mf,n_interactions=0).cuda()\n",
    "net1=HFNet.from_pyscf(mf,n_interactions=1).cuda()\n",
    "net3=HFNet.from_pyscf(mf,n_interactions=3).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler0 = langevin_monte_carlo(\n",
    "    net0,\n",
    "    torch.randn(1000, n_electrons, 3, device='cuda'),\n",
    "    tau=0.1,\n",
    ")\n",
    "\n",
    "sampler1 = langevin_monte_carlo(\n",
    "    net1,\n",
    "    torch.randn(1000, n_electrons, 3, device='cuda'),\n",
    "    tau=0.1,\n",
    ")\n",
    "\n",
    "sampler3 = langevin_monte_carlo(\n",
    "    net3,\n",
    "    torch.randn(1000, n_electrons, 3, device='cuda'),\n",
    "    tau=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for net,sampler in zip([net0,net1,net3],[sampler0,sampler1,sampler3]):\n",
    "    fit_wfnet(\n",
    "        net,\n",
    "        partial(loss_local_energy, E_ref=-1.1,p=2),\n",
    "        torch.optim.Adam(net.parameters(), lr=1e-3),\n",
    "        wfnet_fit_driver(\n",
    "                sampler,\n",
    "                samplings=range(1),\n",
    "                n_epochs=1,\n",
    "                n_sampling_steps=100,\n",
    "                batch_size=1_000,\n",
    "                n_discard=50,\n",
    "                range_sampling=partial(trange, desc='sampling steps', leave=False),\n",
    "                range_training=partial(trange, desc='training steps', leave=False),\n",
    "            ),\n",
    "        clip_grad = None,\n",
    "        writer = SummaryWriter(f'runs/'),\n",
    "        )\n",
    "\n",
    "    fit_wfnet(\n",
    "        net,\n",
    "        partial(loss_local_energy, E_ref=None,p=1),\n",
    "        torch.optim.Adam(net.parameters(), lr=1e-3),\n",
    "        wfnet_fit_driver(\n",
    "                sampler,\n",
    "                samplings=range(1),\n",
    "                n_epochs=1,\n",
    "                n_sampling_steps=100,\n",
    "                batch_size=1_000,\n",
    "                n_discard=50,\n",
    "                range_sampling=partial(trange, desc='sampling steps', leave=False),\n",
    "                range_training=partial(trange, desc='training steps', leave=False),\n",
    "            ),\n",
    "        clip_grad = None,\n",
    "        writer = SummaryWriter(f'runs/'),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_line = torch.cat((torch.linspace(-5, 5, 500)[:, None], torch.zeros((500, 3*n_electrons-1))), dim=1)\n",
    "x_line[:,3]=h2.coords[1][0]/2\n",
    "x_line=x_line.view(-1,n_electrons,3).cuda()\n",
    "x_line.requires_grad = True\n",
    "\n",
    "\n",
    "normed=True\n",
    "normplot(x_line[:,0 , 0].cpu().detach().numpy(), net0(x_line).cpu().detach().numpy(),label=\"WF0\",norm=normed,lw=2)\n",
    "normplot(x_line[:,0 , 0].cpu().detach().numpy(), net1(x_line).cpu().detach().numpy(),label=\"WF1\",norm=normed,lw=2)\n",
    "normplot(x_line[:,0 , 0].cpu().detach().numpy(), net3(x_line).cpu().detach().numpy(),label=\"WF3\",norm=normed,lw=2)\n",
    "plt.axhline(0,ls=':',color='k')\n",
    "plt.axvline(0,ls=':',color='k')\n",
    "plt.axvline(0,ls=':',color='k')\n",
    "x_line.requires_grad = False\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for net,sampler in zip([net0,net1,net3],[sampler0,sampler1,sampler3]):\n",
    "    i+=1\n",
    "    t=time.time()\n",
    "    samples = samples_from(sampler,range(100))[0].flatten(end_dim=1)\n",
    "    print(\"it took: \"+str(time.time()-t))\n",
    "    \n",
    "    E_loc = dlqmc.utils.batch_eval_tuple(partial(local_energy, wf=lambda x: net(x),geom=net.geom),tqdm(samples.view([-1,n_electrons,3]).split(1000)))[0]\n",
    "    E_loc = E_loc.clamp(-4, 1)\n",
    "    mean=E_loc.mean().item()\n",
    "    h = plt.hist(E_loc.detach().cpu().numpy(), bins=100,alpha = 0.5,label=(str(i)+\": mean = \"+str(np.round(mean,4))))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=time.time()\n",
    "samples = samples_from(sampler3,range(100))[0].flatten(end_dim=1)\n",
    "print(\"it took: \"+str(time.time()-t))\n",
    "    \n",
    "plt.hist2d(\n",
    "    samples[:,:, 0].cpu().flatten().detach().numpy(),\n",
    "    samples[:,:, 1].cpu().flatten().detach().numpy(),\n",
    "    bins=100,\n",
    "    range=[[-1, 1], [-1, 1]],\n",
    ")                                   \n",
    "plt.gca().set_aspect(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_loc = dlqmc.utils.batch_eval_tuple(partial(local_energy, wf=lambda x: net0(x),geom=net0.geom),tqdm(samples.view([-1,n_electrons,3]).split(1000)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=np.round(E_loc.clamp(-40, 10).mean().item(),4)\n",
    "var=np.round(np.var(E_loc.detach().clamp(-40, 10).cpu().numpy()),4)\n",
    "\n",
    "h = plt.hist(E_loc.detach().clamp(-40, 10).cpu().numpy(), bins=100,alpha = 0.5,color='b')\n",
    "plt.annotate(\"mean = \"+str(mean),(-0.3,np.max(h[0])/2),color='b')\n",
    "plt.annotate(\"var     = \"+str(var),(-0.3,np.max(h[0])/2-np.max(h[0])/15),color='b')\n",
    "\n",
    "plt.savefig('lastruneloc.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-qmc",
   "language": "python",
   "name": "dl-qmc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
