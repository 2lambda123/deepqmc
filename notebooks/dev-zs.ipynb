{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H2+     Energy = -0.6023424   for R = 1.9972\n",
    "#fit(batch_size=10000, n_el=1, steps=500, epochs=1, RR=[[-1, 0, 0], [1., 0, 0]])\n",
    "\n",
    "#H2\t\t Energy = -1.173427    for R = 1.40\n",
    "#fit(batch_size=10000,n_el=2,steps=100,epochs=5,RR=torch.tensor([[-0.7,0,0],[0.7,0,0]]))\n",
    "\n",
    "#He+\t Energy = -1.9998\n",
    "#fit(batch_size=10000,n_el=1,steps=100,epochs=5,RR=torch.tensor([[0.,0,0]]),RR_charges=[2])\n",
    "\n",
    "#He\t\t Energy = âˆ’2.90338583\n",
    "#fit(batch_size=10000,n_el=2,steps=300,epochs=5,RR=torch.tensor([[0.3,0,0]]),RR_charges=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport  dlqmc.sampling, dlqmc.utils, dlqmc.nn.base, dlqmc.fit\n",
    "%config InlineBackend.figure_format = 'svg' \n",
    "%config InlineBackend.print_figure_kwargs = \\\n",
    "    {'bbox_inches': 'tight', 'dpi': 300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from scipy import special\n",
    "import scipy.stats as sps\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "#from torch.utils.data import DataLoader, RandomSampler\n",
    "#from torch.distributions import Normal\n",
    "from pyscf import gto, scf, dft\n",
    "import pyscf\n",
    "from pyscf.data.nist import BOHR\n",
    "import time\n",
    "from functools import partial\n",
    "from tqdm.auto import tqdm, trange\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from dlqmc.nn.base import * \n",
    "from dlqmc.nn.base import conv_indexing\n",
    "from dlqmc.geom import *\n",
    "from dlqmc.nn.gto import *\n",
    "#from dlqmc.nn import *\n",
    "from dlqmc.sampling import langevin_monte_carlo, hmc ,samples_from\n",
    "from dlqmc.fit import *\n",
    "from dlqmc.nn.anti import *\n",
    "#from dlqmc.utils import assign_where\n",
    "from dlqmc.physics import (\n",
    "    local_energy, grad, quantum_force,nuclear_potential,\n",
    "    nuclear_energy, laplacian, electronic_potential\n",
    ")\n",
    "#from dlqmc.analysis import autocorr_coeff, blocking\n",
    "from dlqmc.nn import ssp\n",
    "from dlqmc.nn.hannet import HanNet\n",
    "from dlqmc.nn.hfnet import HFNet\n",
    "\n",
    "def normplot(x,y,norm,*args,**kwargs):\n",
    "    if norm:\n",
    "        plt.plot(x,y/np.max(np.abs(y)),*args,**kwargs)\n",
    "    else:\n",
    "        plt.plot(x,y,*args,**kwargs)\n",
    "        \n",
    "print(torch.cuda.memory_allocated())\n",
    "print(torch.cuda.memory_cached(device=None))\n",
    "print(torch.cuda.max_memory_cached(device=None))\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from dlqmc.utils import NULL_DEBUG, dctsel, triu_flat\n",
    "from dlqmc.nn.base import (\n",
    "    SSP,\n",
    "    BaseWFNet,\n",
    "    Concat,\n",
    "    DistanceBasis,\n",
    "    ElectronicAsymptotic,\n",
    "    NuclearAsymptotic,\n",
    "    get_log_dnn,\n",
    "    pairwise_distance,\n",
    ")\n",
    "from dlqmc.nn.schnet import ElectronicSchnet\n",
    "from dlqmc.nn.hfnet import HFNet\n",
    "from dlqmc.nn.backflow import Backflow\n",
    "\n",
    "\n",
    "\n",
    "class SJNet(BaseWFNet):\n",
    "    def __init__(\n",
    "        self,\n",
    "        geom,\n",
    "        n_up,\n",
    "        n_down,\n",
    "        mf,\n",
    "        basis_dim=32,\n",
    "        kernel_dim=64,\n",
    "        embedding_dim=128,\n",
    "        n_interactions=3,\n",
    "        n_orbital_layers=3,\n",
    "        ion_pot=0.,\n",
    "        cusp_same=None,\n",
    "        cusp_anti=None,\n",
    "        #nuc_asymp=True,\n",
    "\n",
    "        **kwargs,\n",
    "    ):\n",
    "        def orbital_factory(embedding_dim):\n",
    "            return get_log_dnn(embedding_dim, 1, SSP, n_layers=n_orbital_layers)\n",
    "\n",
    "\n",
    "        super().__init__()\n",
    "        self.n_up = n_up\n",
    "        self.register_geom(geom)\n",
    "        self.dist_basis = DistanceBasis(basis_dim, **dctsel(kwargs, 'cutoff'))\n",
    "        #self.nuc_asymp = nuc_asymp\n",
    "        self.asymp_nuc = NuclearAsymptotic(\n",
    "                self.charges, ion_pot, **dctsel(kwargs, 'alpha')\n",
    "        )\n",
    "\n",
    "        self.asymp_same, self.asymp_anti = (\n",
    "            ElectronicAsymptotic(cusp=cusp) if cusp is not None else None\n",
    "            for cusp in (cusp_same, cusp_anti)\n",
    "        )\n",
    "        self.schnet = ElectronicSchnet(\n",
    "            n_up,\n",
    "            n_down,\n",
    "            len(geom),\n",
    "            n_interactions,\n",
    "            basis_dim,\n",
    "            kernel_dim,\n",
    "            embedding_dim,\n",
    "            interaction_factory=None,\n",
    "        )\n",
    "        self.orbital = orbital_factory(embedding_dim)\n",
    "        self.anti = HFNet.from_pyscf(mf)\n",
    "\n",
    "    def forward(self, rs, debug=NULL_DEBUG):\n",
    "        dists_elec = pairwise_distance(rs, rs)\n",
    "        dists_nuc = pairwise_distance(rs, self.coords[None, ...])\n",
    "        dists = torch.cat([dists_elec, dists_nuc], dim=2)\n",
    "        dists_basis = self.dist_basis(dists)\n",
    "        with debug.cd('schnet'):\n",
    "            xs = self.schnet(dists_basis, debug=debug)\n",
    "        jastrow = debug['jastrow'] = self.orbital(xs).squeeze(dim=-1).sum(dim=-1)\n",
    "        anti = debug['anti'] = self.anti(rs)\n",
    "        \n",
    "       # if self.nuc_asymp:\n",
    "       #     asymp_nuc = debug['asymp_nuc'] = self.asymp_nuc(dists_nuc)  # TODO add electrons\n",
    "       # else:\n",
    "       #     asymp_nuc = 1.\n",
    "        asymp_same = debug['asymp_same'] = (\n",
    "            self.asymp_same(\n",
    "                torch.cat(\n",
    "                    [triu_flat(dists_elec[:, idxs, idxs]) for idxs in self.spin_slices],\n",
    "                    dim=1,\n",
    "                )\n",
    "            )\n",
    "            if self.asymp_same\n",
    "            else 1.0\n",
    "        )\n",
    "        asymp_anti = debug['asymp_anti'] = (\n",
    "            self.asymp_anti(\n",
    "                dists_elec[:, : self.n_up, self.n_up :].flattten(start_dim=1)\n",
    "            )\n",
    "            if self.asymp_anti\n",
    "            else 1.0\n",
    "        )\n",
    "        \n",
    "        asymp = asymp_same * asymp_anti# * asymp_nuc \n",
    "\n",
    "        return anti * torch.exp(jastrow) * asymp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2p = geomdb['H2+']\n",
    "h2 = geomdb['H2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "\n",
    "class SlaterSchnetJastrowNet(BaseWFNet):\n",
    "    def __init__(self, geom, n_up, n_down,\n",
    "                 \n",
    "        basis_dim=32,\n",
    "                 \n",
    "        kernel_dim_jastrow=64,\n",
    "        embedding_dim_jastrow=128,\n",
    "        n_interactions_jastrow=3,\n",
    "                 \n",
    "        kernel_dim_anti=64,\n",
    "        embedding_dim_anti=128,\n",
    "        n_interactions_anti=3,\n",
    "                 \n",
    "        ion_pot=1.,\n",
    "        n_orbital_layers=4,\n",
    "        **kwargs):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.n_up, self.n_down = n_up, n_down\n",
    "        self.register_geom(geom)\n",
    "        self.dist_basis = DistanceBasis(basis_dim, **dctsel(kwargs, 'cutoff'))\n",
    "        self.mo = nn.Linear(embedding_dim_anti, max(n_up, n_down), bias=False)\n",
    "        self.schnet_anti = ElectronicSchnet(\n",
    "            n_up,\n",
    "            n_down,\n",
    "            len(geom),\n",
    "            n_interactions_anti,\n",
    "            basis_dim,\n",
    "            kernel_dim_anti,\n",
    "            embedding_dim_anti,\n",
    "            interaction_factory=None,\n",
    "        )\n",
    "        self.schnet = ElectronicSchnet(\n",
    "            n_up,\n",
    "            n_down,\n",
    "            len(geom),\n",
    "            n_interactions_jastrow,\n",
    "            basis_dim,\n",
    "            kernel_dim_jastrow,\n",
    "            embedding_dim_jastrow,\n",
    "            interaction_factory=None,\n",
    "        )\n",
    "        \n",
    "        self.asymp_nuc = NuclearAsymptotic(\n",
    "                self.charges, ion_pot, **dctsel(kwargs, 'alpha')\n",
    "        )\n",
    "\n",
    "        \n",
    "        def orbital_factory(embedding_dim):\n",
    "            return get_log_dnn(embedding_dim, 1, SSP, n_layers=n_orbital_layers)\n",
    "        \n",
    "        self.orbital = orbital_factory(embedding_dim_jastrow)\n",
    "\n",
    "    def __call__(self, rs, debug=NULL_DEBUG):\n",
    "        \n",
    "        dists_elec  = pairwise_distance(rs, rs)\n",
    "        dists_nuc   = pairwise_distance(rs, self.coords[None, ...])\n",
    "        dists       = torch.cat([dists_elec, dists_nuc], dim=2)\n",
    "        dists_basis = self.dist_basis(dists)\n",
    "        \n",
    "        batch_dim, n_elec = rs.shape[:2]\n",
    "        \n",
    "        asymp_nuc = self.asymp_nuc(dists_nuc)\n",
    "        \n",
    "        xs = self.schnet(dists_basis)\n",
    "        jastrow = self.orbital(xs).squeeze(dim=-1).sum(dim=-1)\n",
    "        \n",
    "        ys = self.schnet_anti(dists_basis)\n",
    "        ys = self.mo(ys)\n",
    "\n",
    "        det_up = debug['det_up'] = eval_slater(ys[:, : self.n_up, : self.n_up])\n",
    "        det_down = debug['det_down'] = eval_slater(ys[:, self.n_up :, : self.n_down])\n",
    "\n",
    "        return det_up * det_down * jastrow \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $H_{10}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from dlqmc.sampling import sample_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Han -5.5685, Benschmark -5.6655"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=1.786\n",
    "n=10\n",
    "hn = Geometry([[d*i, 0., 0.] for i in range(n)], [1. for i in range (n)])\n",
    "print(hn)\n",
    "molecule = hn\n",
    "n_electrons=n\n",
    "n_down = n//2\n",
    "n_up = n_electrons-n_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = gto.M(\n",
    "    atom=[\n",
    "        ['H', (d*i, 0, 0)] for i in range(n)      \n",
    "    ],\n",
    "    unit='bohr',\n",
    "    basis='6-31G',#'aug-cc-pV5Z',\n",
    "    charge=0,\n",
    "    spin=n%2,\n",
    "    cart=True\n",
    ")\n",
    "mf = scf.RHF(mol)\n",
    "mf.kernel()\n",
    "gtowf = HFNet.from_pyscf(mf).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hannet = HanNet(hn,n_up,n_down, \n",
    "#        basis_dim=16,\n",
    "#        kernel_dim=32,\n",
    "#        embedding_dim=64,\n",
    "#        latent_dim=10,\n",
    "#        n_interactions=3,\n",
    "#        n_orbital_layers=3,).cuda()\n",
    "\n",
    "#sjnet = SJNet(hn,n_up,n_down, mf=mf,\n",
    "#        basis_dim=16,\n",
    "#        kernel_dim=32,\n",
    "#        embedding_dim=64,\n",
    "#        latent_dim=10,\n",
    "#        n_interactions=3,\n",
    "#        n_orbital_layers=3,\n",
    "#        ).cuda()\n",
    "\n",
    "ssjnet = SlaterSchnetJastrowNet(hn,n_up,n_down, \n",
    "        ).cuda()\n",
    "\n",
    "\n",
    "#sjnet_nuc = SJNet(hn,n_up,n_down, mf=mf,\n",
    "#        basis_dim=16,\n",
    "#        kernel_dim=32,\n",
    "#        embedding_dim=64,\n",
    "#        latent_dim=10,\n",
    "#        n_interactions=3,\n",
    "#        n_orbital_layers=3,\n",
    "#        nuc_asymp=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_wlaker=5\n",
    "#samplerhan = langevin_monte_carlo(\n",
    "#    hannet,\n",
    "#    sample_start(molecule,n_wlaker,n_electrons,var=1),\n",
    "#    tau=0.1,\n",
    "#)\n",
    "#samplersj = langevin_monte_carlo(\n",
    "#    sjnet,\n",
    "#    sample_start(molecule,n_wlaker,n_electrons,var=1),\n",
    "#    tau=0.1,\n",
    "#)\n",
    "samplerssj = langevin_monte_carlo(\n",
    "    ssjnet,\n",
    "    sample_start(molecule,n_wlaker,n_electrons,var=1),\n",
    "    tau=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "samplergto = langevin_monte_carlo(\n",
    "    gtowf,\n",
    "    sample_start(molecule,n_wlaker,n_electrons,var=1),\n",
    "    tau=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def run():\n",
    "fit_wfnet_supervised(\n",
    "        ssjnet,\n",
    "        gtowf.cuda(),\n",
    "        loss_least_squares,\n",
    "        torch.optim.Adam(ssjnet.parameters(), lr=1e-3),\n",
    "        wfnet_fit_driver(\n",
    "                samplerssj,\n",
    "                samplings=range(20),\n",
    "                n_epochs=1,\n",
    "                n_sampling_steps=50,\n",
    "                batch_size=1_000,\n",
    "                n_discard=30,\n",
    "                range_sampling=partial(trange, desc='sampling steps', leave=False),\n",
    "                range_training=partial(trange, desc='training steps', leave=False),\n",
    "            ),\n",
    "        writer =  SummaryWriter(f'runs/'),\n",
    "        )\n",
    "\n",
    "\n",
    "for net,sampler in zip([ssjnet],[samplerssj]):\n",
    "    fit_wfnet(\n",
    "        net,\n",
    "        partial(loss_local_energy, E_ref=-6,p=1),\n",
    "        torch.optim.Adam(net.parameters(), lr=1e-3),\n",
    "        wfnet_fit_driver_simple(\n",
    "                sampler,\n",
    "                samplings=trange(500),\n",
    "                n_sampling_steps=50,\n",
    "                n_decorrelate = 4,\n",
    "                n_discard = 30\n",
    "            ),\n",
    "        clip_grad = None,\n",
    "        writer = SummaryWriter(f'runs/'),\n",
    "        )\n",
    "\n",
    "    fit_wfnet(\n",
    "        net,\n",
    "        partial(loss_local_energy, E_ref=None,p=1),\n",
    "        torch.optim.Adam(net.parameters(), lr=1e-3),\n",
    "        wfnet_fit_driver_simple(\n",
    "                sampler,\n",
    "                samplings=trange(1000),\n",
    "                n_sampling_steps=50,\n",
    "                n_decorrelate = 4,\n",
    "                n_discard = 30,\n",
    "            ),\n",
    "        clip_grad = None,\n",
    "        acc_grad = 5,\n",
    "        writer = SummaryWriter(f'runs/'),\n",
    "    )\n",
    "\n",
    "#t = threading.Thread(target=run)\n",
    "#t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_line = torch.cat((torch.linspace(-d, (n_electrons)*d, 500)[:, None], torch.zeros((500, 3*n_electrons-1))), dim=1)\n",
    "for i in range(n_electrons-1):\n",
    "    x_line[:,3*(i+1)]=d/2*(2*(i))+torch.randn(1)/10\n",
    "    #x_line[:,3*(i+1)+1]=torch.randn(1)/10\n",
    "    #x_line[:,3*(i+1)+2]=torch.randn(1)/10\n",
    "x_line=x_line.view(-1,n_electrons,3).cuda()\n",
    "#x_line=x_line[:,[0,3,2,1]]\n",
    "x_line.requires_grad = True\n",
    "\n",
    "\n",
    "\n",
    "normed=True\n",
    "normplot(x_line[:,0 , 0].cpu().detach().numpy(), ssjnet(x_line).cpu().detach().numpy(),label=\"ssjWF\",norm=normed)\n",
    "normplot(x_line[:,0 , 0].cpu().detach().numpy(), hannet(x_line).cpu().detach().numpy(),label=\"hanWF\",norm=normed)\n",
    "normplot(x_line[:,0 , 0].cpu().detach().numpy(), sjnet(x_line).cpu().detach().numpy(),label=\"sjWF\",norm=normed)\n",
    "normplot(x_line[:,0 , 0].cpu().detach().numpy(), gtowf(x_line).cpu().detach().numpy(),ls=':',label=\"HF\",norm=normed)\n",
    "\n",
    "plt.axhline(0,ls=':',color='k')\n",
    "for i in range(n):\n",
    "    plt.axvline(d*i,ls=':',color='k')\n",
    "for i in range(n_electrons-1):\n",
    "    plt.axvline(x_line[0,(i+1)][0],ls=':',color='r')\n",
    "\n",
    "\n",
    "#plt.ylim(-1,2)\n",
    "x_line.requires_grad = False\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for net,sampler in zip([ssjnet,sjnet,hannet],[samplerssj,samplersj,samplerhan]):\n",
    "    t=time.time()\n",
    "    samples = samples_from(sampler,trange(1000))[0].flatten(end_dim=1)\n",
    "    print(\"it took: \"+str(time.time()-t))\n",
    "    E_loc = dlqmc.utils.batch_eval_tuple(partial(local_energy, wf=lambda x: net(x),geom=net.geom),tqdm(samples.view([-1,n_electrons,3]).split(1000)))[0]\n",
    "    E_loc = E_loc.clamp(-4, -0)\n",
    "    mean=E_loc.mean().item()\n",
    "    h = plt.hist(E_loc.detach().cpu().numpy(), bins=100,alpha = 0.5,label=(\"mean = \"+str(np.round(mean,4))))\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit as cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p2(x,a,c):\n",
    "    return a+c*x**2\n",
    "def p1(x,a,c):\n",
    "    return a+c*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_p = []\n",
    "m_alloc = []\n",
    "m_max_alloc = []\n",
    "m_cached = []\n",
    "m_max_cached = []\n",
    "T_forward=[]\n",
    "T_eloc=[]\n",
    "for n in trange(1,40):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    d=1.5#1.786\n",
    "    hn = Geometry([[d*i, 0., 0.] for i in range(n)], [1. for i in range (n)])\n",
    "\n",
    "    n_electrons=n\n",
    "    n_up = n//2\n",
    "    n_down = n_electrons-n_up\n",
    "    net = HanNet(hn,n_up,n_down, \n",
    "            basis_dim=8,\n",
    "            kernel_dim=16,\n",
    "            embedding_dim=32,\n",
    "            latent_dim=5,\n",
    "            n_interactions=2,\n",
    "            n_orbital_layers=3,).cuda()\n",
    "\n",
    "\n",
    "    n=0\n",
    "    for p in net.parameters():\n",
    "        n+=torch.prod(torch.tensor(p.shape))\n",
    "    n_p.append(n)\n",
    "    \n",
    "    sampler = langevin_monte_carlo(\n",
    "    net,\n",
    "    torch.randn(10, n_electrons, 3, device='cuda'),\n",
    "    tau=0.1,\n",
    "    )\n",
    "\n",
    "    samples = samples_from(sampler,range(10))[0].flatten(end_dim=1)\n",
    "\n",
    "    T = []\n",
    "    for j in range(10):\n",
    "        t = time.time()\n",
    "        y = net(samples)\n",
    "        T.append(time.time()-t)\n",
    "    T_forward.append(np.mean(np.array(T)))\n",
    "    \n",
    "    T = []\n",
    "    for j in range(10):\n",
    "        t = time.time()\n",
    "        local_energy(samples,net)\n",
    "        T.append(time.time()-t)\n",
    "    T_eloc.append(np.mean(np.array(T)))\n",
    "\n",
    "    m_alloc.append(torch.cuda.memory_allocated())\n",
    "    m_max_alloc.append(torch.cuda.max_memory_allocated())\n",
    "    m_cached.append(torch.cuda.memory_cached(device=None))\n",
    "    m_max_cached.append(torch.cuda.max_memory_cached(device=None))\n",
    "    \n",
    "    del hn\n",
    "    del net\n",
    "    del sampler\n",
    "    del samples\n",
    "    torch.cuda.empty_cache()\n",
    "    #print(torch.cuda.memory_allocated())\n",
    "    #print(torch.cuda.memory_cached(device=None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.arange(1,40)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"scaling\")\n",
    "plt.subplot2grid((2,2),(0,0))\n",
    "plt.plot(x,p1(x,*cf(p1,x,n_p)[0]))\n",
    "plt.plot(x,n_p,ls='',marker='x')\n",
    "#plt.annotate(xy=(5,5850),s=\"f(x) = a+bx\\n a=%1.1f\\n b=%1.1f \"%tuple(cf(p1,x,n_p)[0]))\n",
    "plt.xlabel(\"# hydrogen atoms\")\n",
    "plt.ylabel(\"# parameters\")\n",
    "plt.subplot2grid((2,2),(0,1))\n",
    "#plt.plot(x,m_alloc)\n",
    "plt.plot(x,p2(x,*cf(p2,x,m_max_alloc)[0]))\n",
    "plt.plot(x,m_max_alloc,ls='',marker='x')\n",
    "#plt.annotate(xy=(5,3e7),s=\"f(x) = a+bx^2\\n a=%1.1f\\n b=%1.1f \"%tuple(cf(p2,x,m_max_alloc)[0]))\n",
    "plt.xlabel(\"# hydrogen atoms\")\n",
    "plt.ylabel(\"memory allocated\")\n",
    "plt.subplot2grid((2,2),(1,0))\n",
    "plt.plot(x,p1(x,*cf(p1,x,T_forward)[0]))\n",
    "plt.plot(x,T_forward,ls='',marker='x')\n",
    "plt.ylabel(\"time forward\")\n",
    "plt.xlabel(\"# hydrogen atoms\")\n",
    "plt.subplot2grid((2,2),(1,1))\n",
    "plt.plot(x,p2(x,*cf(p2,x,T_eloc)[0]))\n",
    "plt.plot(x,T_eloc,ls='',marker='x')\n",
    "plt.ylabel(\"time local energy\")\n",
    "plt.xlabel(\"# hydrogen atoms\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = gto.M(\n",
    "    atom=[\n",
    "        ['B', (0, 0, 0)]\n",
    "    ],\n",
    "    unit='bohr',\n",
    "    basis='4-31G',\n",
    "    cart=True,\n",
    "    charge=0,\n",
    "    spin=1,\n",
    ")\n",
    "mf = scf.RHF(mol)\n",
    "mf.kernel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bohr=geomdb['H']\n",
    "bohr._coords=torch.tensor([[0,0,0.]])\n",
    "bohr._charges=torch.tensor([5.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from dlqmc.geom import Geometry\n",
    "from dlqmc.utils import NULL_DEBUG\n",
    "from dlqmc.nn.anti import eval_slater\n",
    "from dlqmc.nn.base import BaseWFNet\n",
    "from dlqmc.nn.base import DistanceBasis\n",
    "from dlqmc.nn.gto import GTOBasis\n",
    "from dlqmc.nn.backflow import Backflow\n",
    "\n",
    "\n",
    "class HFNet(BaseWFNet):\n",
    "    def __init__(self, geom, n_up, n_down, basis, n_interactions):\n",
    "        super().__init__()\n",
    "        self.n_up, self.n_down = n_up, n_down\n",
    "        self.register_geom(geom)\n",
    "        self.basis = basis\n",
    "        self.mo = nn.Linear(basis.dim, max(n_up, n_down), bias=False)\n",
    "        self.backflow = Backflow(n_up, n_down,n_interactions,4,20)\n",
    "\n",
    "    def init_from_pyscf(self, mf):\n",
    "        mo_coeff = mf.mo_coeff.copy()\n",
    "        if mf.mol.cart:\n",
    "            mo_coeff *= np.sqrt(np.diag(mf.mol.intor('int1e_ovlp_cart')))[:, None]\n",
    "        self.mo.weight.detach().copy_(\n",
    "            torch.from_numpy(mo_coeff[:, : max(self.n_up, self.n_down)].T)\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_pyscf(cls, mf, n_interactions):\n",
    "        n_up = (mf.mo_occ >= 1).sum()\n",
    "        n_down = (mf.mo_occ == 2).sum()\n",
    "        assert (mf.mo_occ[:n_down] == 2).all()\n",
    "        assert (mf.mo_occ[n_down:n_up] == 1).all()\n",
    "        assert (mf.mo_occ[n_up:] == 0).all()\n",
    "        geom = Geometry(mf.mol.atom_coords().astype('float32'), mf.mol.atom_charges())\n",
    "        basis = GTOBasis.from_pyscf(mf.mol)\n",
    "        wf = cls(geom, n_up, n_down, basis, n_interactions)\n",
    "        wf.init_from_pyscf(mf)\n",
    "        return wf\n",
    "\n",
    "    def __call__(self, rs, debug=NULL_DEBUG):\n",
    "        batch_dim, n_elec = rs.shape[:2]\n",
    "        xs = self.backflow(rs)\n",
    "        xs = debug['aos'] = self.basis(rs.flatten(end_dim=1)).view(batch_dim, n_elec, -1)\n",
    "        xs = debug['slaters'] = self.mo(xs)\n",
    "        det_up = debug['det_up'] = eval_slater(xs[:, : self.n_up, : self.n_up])\n",
    "        det_down = debug['det_down'] = eval_slater(xs[:, self.n_up :, : self.n_down])\n",
    "        return det_up * det_down\n",
    "\n",
    "    def orbitals(self, rs):\n",
    "        return self.mo(self.basis(rs))\n",
    "\n",
    "    def density(self, rs):\n",
    "        xs = self.orbitals(rs)\n",
    "        return sum(\n",
    "            (xs[:, :n_elec] ** 2).sum(dim=-1) for n_elec in (self.n_up, self.n_down)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_electrons=5\n",
    "n_up = 3\n",
    "n_down = n_electrons-n_up\n",
    "molecule = bohr\n",
    "\n",
    "net0=HFNet.from_pyscf(mf,n_interactions=0).cuda()\n",
    "net1=HFNet.from_pyscf(mf,n_interactions=1).cuda()\n",
    "net3=HFNet.from_pyscf(mf,n_interactions=3).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler0 = langevin_monte_carlo(\n",
    "    net0,\n",
    "    torch.randn(1000, n_electrons, 3, device='cuda'),\n",
    "    tau=0.1,\n",
    ")\n",
    "\n",
    "sampler1 = langevin_monte_carlo(\n",
    "    net1,\n",
    "    torch.randn(1000, n_electrons, 3, device='cuda'),\n",
    "    tau=0.1,\n",
    ")\n",
    "\n",
    "sampler3 = langevin_monte_carlo(\n",
    "    net3,\n",
    "    torch.randn(1000, n_electrons, 3, device='cuda'),\n",
    "    tau=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for net,sampler in zip([net0,net1],[sampler0,sampler1]):\n",
    "    fit_wfnet(\n",
    "        net,\n",
    "        partial(loss_local_energy, E_ref=-1.1,p=2),\n",
    "        torch.optim.Adam(net.parameters(), lr=1e-3),\n",
    "        wfnet_fit_driver(\n",
    "                sampler,\n",
    "                samplings=range(1),\n",
    "                n_epochs=1,\n",
    "                n_sampling_steps=200,\n",
    "                batch_size=1_000,\n",
    "                n_discard=50,\n",
    "                range_sampling=partial(trange, desc='sampling steps', leave=False),\n",
    "                range_training=partial(trange, desc='training steps', leave=False),\n",
    "            ),\n",
    "        clip_grad = None,\n",
    "        writer = SummaryWriter(f'runs/'),\n",
    "        )\n",
    "\n",
    "    fit_wfnet(\n",
    "        net,\n",
    "        partial(loss_local_energy, E_ref=None,p=1),\n",
    "        torch.optim.Adam(net.parameters(), lr=1e-3),\n",
    "        wfnet_fit_driver(\n",
    "                sampler,\n",
    "                samplings=range(3),\n",
    "                n_epochs=1,\n",
    "                n_sampling_steps=200,\n",
    "                batch_size=1_000,\n",
    "                n_discard=50,\n",
    "                range_sampling=partial(trange, desc='sampling steps', leave=False),\n",
    "                range_training=partial(trange, desc='training steps', leave=False),\n",
    "            ),\n",
    "        clip_grad = None,\n",
    "        writer = SummaryWriter(f'runs/'),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_line = torch.cat((torch.linspace(-5, 5, 599)[:, None], torch.zeros((599, 3*n_electrons-1))), dim=1)\n",
    "x_line[:,3]=0.4\n",
    "x_line[:,4]=0.1\n",
    "x_line[:,5]=-0.1\n",
    "x_line[:,6]=-0.2\n",
    "x_line[:,7]=-0.2\n",
    "x_line[:,8]=-0.2\n",
    "x_line[:,10]=0.4\n",
    "x_line[:,13]=-0.2\n",
    "\n",
    "x_line=x_line.view(-1,n_electrons,3).cuda()\n",
    "x_line.requires_grad = True\n",
    "\n",
    "\n",
    "normed=True\n",
    "normplot(x_line[:,0 , 0].cpu().detach().numpy(), net0(x_line).cpu().detach().numpy(),label=\"WF0\",norm=normed,lw=2)\n",
    "normplot(x_line[:,0 , 0].cpu().detach().numpy(), net1(x_line).cpu().detach().numpy(),label=\"WF1\",norm=normed,lw=2)\n",
    "#normplot(x_line[:,0 , 0].cpu().detach().numpy(), net3(x_line).cpu().detach().numpy(),label=\"WF3\",norm=normed,lw=2)\n",
    "plt.axhline(0,ls=':',color='k')\n",
    "plt.axvline(0,ls=':',color='k')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for net,sampler in zip([net0,net1],[sampler0,sampler1]):\n",
    "    i+=1\n",
    "    t=time.time()\n",
    "    samples = samples_from(sampler,range(100))[0].flatten(end_dim=1)\n",
    "    print(\"it took: \"+str(time.time()-t))\n",
    "    \n",
    "    E_loc = dlqmc.utils.batch_eval_tuple(partial(local_energy, wf=lambda x: net(x),geom=net.geom),tqdm(samples.view([-1,n_electrons,3]).split(1000)))[0]\n",
    "    E_loc = E_loc.clamp(-40, 10)\n",
    "    mean=E_loc.mean().item()\n",
    "    h = plt.hist(E_loc.detach().cpu().numpy(), bins=100,alpha = 0.5,label=(str(i)+\": mean = \"+str(np.round(mean,4))))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=time.time()\n",
    "samples = samples_from(sampler3,range(100))[0].flatten(end_dim=1)\n",
    "print(\"it took: \"+str(time.time()-t))\n",
    "    \n",
    "plt.hist2d(\n",
    "    samples[:,:, 0].cpu().flatten().detach().numpy(),\n",
    "    samples[:,:, 1].cpu().flatten().detach().numpy(),\n",
    "    bins=100,\n",
    "    range=[[-1, 1], [-1, 1]],\n",
    ")                                   \n",
    "plt.gca().set_aspect(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_loc = dlqmc.utils.batch_eval_tuple(partial(local_energy, wf=lambda x: net0(x),geom=net0.geom),tqdm(samples.view([-1,n_electrons,3]).split(1000)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=np.round(E_loc.clamp(-40, 10).mean().item(),4)\n",
    "var=np.round(np.var(E_loc.detach().clamp(-40, 10).cpu().numpy()),4)\n",
    "\n",
    "h = plt.hist(E_loc.detach().clamp(-40, 10).cpu().numpy(), bins=100,alpha = 0.5,color='b')\n",
    "plt.annotate(\"mean = \"+str(mean),(-0.3,np.max(h[0])/2),color='b')\n",
    "plt.annotate(\"var     = \"+str(var),(-0.3,np.max(h[0])/2-np.max(h[0])/15),color='b')\n",
    "\n",
    "plt.savefig('lastruneloc.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssjnet = SlaterSchnetJastrowNet(hn,n_up,n_down, \n",
    "        ).cuda()\n",
    "\n",
    "samplerssj = langevin_monte_carlo(\n",
    "    ssjnet,\n",
    "    sample_start(molecule,2000,n_electrons,var=1),\n",
    "    tau=0.1,\n",
    ")\n",
    "samplergto = langevin_monte_carlo(\n",
    "    gtowf,\n",
    "    sample_start(molecule,2000,n_electrons,var=1),\n",
    "    tau=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_wfnet_supervised(\n",
    "    ssjnet,\n",
    "    gtowf.cuda(),\n",
    "    loss_least_squares,\n",
    "    torch.optim.Adam(ssjnet.parameters(), lr=1e-3),\n",
    "    wfnet_fit_driver(\n",
    "            samplerssj,\n",
    "            samplings=range(1),\n",
    "            n_epochs=1,\n",
    "            n_sampling_steps=50,\n",
    "            batch_size=1_000,\n",
    "            n_discard=30,\n",
    "            range_sampling=partial(trange, desc='sampling steps', leave=False),\n",
    "            range_training=partial(trange, desc='training steps', leave=False),\n",
    "        ),\n",
    "    writer =  SummaryWriter(f'runs/'),\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_line = torch.cat((torch.linspace(-d, (n_electrons)*d, 500)[:, None], torch.zeros((500, 3*n_electrons-1))), dim=1)\n",
    "for i in range(n_electrons-1):\n",
    "    x_line[:,3*(i+1)]=d/2*(2*(i+1))+torch.randn(1)/2\n",
    "    #x_line[:,3*(i+1)+1]=torch.randn(1)/10\n",
    "    #x_line[:,3*(i+1)+2]=torch.randn(1)/10\n",
    "x_line=x_line.view(-1,n_electrons,3).cuda()\n",
    "\n",
    "\n",
    "\n",
    "normed=True\n",
    "normplot(x_line[:,0 , 0].cpu().detach().numpy(), (ssjnet(x_line)).cpu().detach().numpy(),label=\"ssjnet\",norm=normed)\n",
    "normplot(x_line[:,0 , 0].cpu().detach().numpy(), (gtowf(x_line)).cpu().detach().numpy(),label=\"gtoWF\",norm=normed)\n",
    "\n",
    "#x_line=x_line[:,[0,2,1]]\n",
    "#\n",
    "#normplot(x_line[:,0 , 0].cpu().detach().numpy(), (ssjnet(x_line)).cpu().detach().numpy(),label=\"ssjnet\",norm=normed)\n",
    "#normplot(x_line[:,0 , 0].cpu().detach().numpy(), (gtowf(x_line)).cpu().detach().numpy(),label=\"gtoWF\",norm=normed)\n",
    "\n",
    "plt.axhline(0,ls=':',color='k')\n",
    "for i in range(n):\n",
    "    plt.axvline(d*i,ls=':',color='k')\n",
    "for i in range(n_electrons-1):\n",
    "    plt.axvline(x_line[0,(i+1)][0],ls=':',color='r')\n",
    "\n",
    "\n",
    "#plt.ylim(-1,2)\n",
    "x_line.requires_grad = False\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-qmc",
   "language": "python",
   "name": "dl-qmc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
