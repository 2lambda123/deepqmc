{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H2+     Energy = -0.6023424   for R = 1.9972\n",
    "#fit(batch_size=10000, n_el=1, steps=500, epochs=1, RR=[[-1, 0, 0], [1., 0, 0]])\n",
    "\n",
    "#H2\t\t Energy = -1.173427    for R = 1.40\n",
    "#fit(batch_size=10000,n_el=2,steps=100,epochs=5,RR=torch.tensor([[-0.7,0,0],[0.7,0,0]]))\n",
    "\n",
    "#He+\t Energy = -1.9998\n",
    "#fit(batch_size=10000,n_el=1,steps=100,epochs=5,RR=torch.tensor([[0.,0,0]]),RR_charges=[2])\n",
    "\n",
    "#He\t\t Energy = âˆ’2.90338583\n",
    "#fit(batch_size=10000,n_el=2,steps=300,epochs=5,RR=torch.tensor([[0.3,0,0]]),RR_charges=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport  dlqmc.sampling, dlqmc.utils, dlqmc.nn.base, dlqmc.fit\n",
    "%config InlineBackend.figure_format = 'svg' \n",
    "%config InlineBackend.print_figure_kwargs = \\\n",
    "    {'bbox_inches': 'tight', 'dpi': 300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from scipy import special\n",
    "import scipy.stats as sps\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "#from torch.utils.data import DataLoader, RandomSampler\n",
    "#from torch.distributions import Normal\n",
    "from pyscf import gto, scf, dft\n",
    "import pyscf\n",
    "from pyscf.data.nist import BOHR\n",
    "import time\n",
    "from functools import partial\n",
    "from tqdm.auto import tqdm, trange\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from dlqmc.nn.base import * \n",
    "from dlqmc.geom import *\n",
    "from dlqmc.gto import *\n",
    "from dlqmc.nn import *\n",
    "from dlqmc.sampling import langevin_monte_carlo, hmc ,samples_from\n",
    "from dlqmc.fit import *\n",
    "#from dlqmc.utils import assign_where\n",
    "from dlqmc.physics import (\n",
    "    local_energy, grad, quantum_force,nuclear_potential,\n",
    "    nuclear_energy, laplacian, electronic_potential\n",
    ")\n",
    "#from dlqmc.analysis import autocorr_coeff, blocking\n",
    "from dlqmc.nn import ssp\n",
    "from dlqmc.nn.hannet import HanNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normplot(x,y,norm,*args,**kwargs):\n",
    "    if norm:\n",
    "        plt.plot(x,y/np.max(np.abs(y)),*args,**kwargs)\n",
    "    else:\n",
    "        plt.plot(x,y,*args,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_pair(nn.Module):\n",
    "    def __init__(self,geom,n_dist_feats=32):\n",
    "        super().__init__()\n",
    "        self.dist_basis = DistanceBasis(n_dist_feats)\n",
    "        self.register_buffer('coords', geom.coords)\n",
    "        self.register_buffer('charges', geom.charges)\n",
    "        self.NN1=nn.Sequential(\n",
    "            torch.nn.Linear(6, 10),\n",
    "            SSP(),\n",
    "            #torch.nn.Linear(10, 10),\n",
    "            #SSP(),\n",
    "            torch.nn.Linear(10, 10)\n",
    "            )\n",
    "        \n",
    "    def forward(self,x1,x2):\n",
    "        d=torch.cat((x1,x2),dim=-1)\n",
    "        return self.NN1(d).view(-1,10)\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.NN1=nn.Sequential(\n",
    "            torch.nn.Linear(10, 10),\n",
    "            SSP(),\n",
    "            #torch.nn.Linear(15, 10),\n",
    "            #SSP(),\n",
    "            torch.nn.Linear(10, 1))#,\n",
    "            #nn.Sigmoid())\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        return torch.sigmoid(self.NN1(x).flatten())\n",
    "\n",
    "    \n",
    "class WFNetAnti(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        geom,\n",
    "        n_electrons,\n",
    "        net,\n",
    "        net_pair,\n",
    "        ion_pot=0.5,\n",
    "        cutoff=10.0,\n",
    "        n_dist_feats=32,\n",
    "        alpha=1.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dist_basis = DistanceBasis(n_dist_feats)\n",
    "        self.register_buffer('coords', geom.coords)\n",
    "        self.register_buffer('charges', geom.charges)\n",
    "        self.nuc_asymp = NuclearAsymptotic(self.charges, ion_pot, alpha=alpha)\n",
    "        #self.el_cusp = ElectronicCusp()\n",
    "        n_atoms = len(geom.charges)\n",
    "        n_pairs = n_electrons * n_atoms + n_electrons * (n_electrons - 1) // 2\n",
    "        self.deep_lin = nn.Sequential(\n",
    "            nn.Linear(n_pairs * n_dist_feats, 64),\n",
    "            SSP(),\n",
    "            nn.Linear(64, 64),\n",
    "            SSP(),\n",
    "            nn.Linear(64, 64),\n",
    "            SSP(),\n",
    "            nn.Linear(64, 64),\n",
    "            SSP(),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "        self.antisym = AntisymmetricPart(net, net_pair)\n",
    "        self._pdist = PairwiseDistance3D()\n",
    "        self._psdist = PairwiseSelfDistance3D()\n",
    "\n",
    "    def _featurize(self, rs):\n",
    "        dists_nuc = self._pdist(rs, self.coords[None, ...])\n",
    "        dists_el = self._psdist(rs)\n",
    "        dists = torch.cat([dists_nuc.flatten(start_dim=1), dists_el], dim=1)\n",
    "        xs = self.dist_basis(dists)  # .flatten(start_dim=1)\n",
    "        return xs.flatten(start_dim=1), (dists_nuc, dists_el)\n",
    "\n",
    "    def forward(self, rs):\n",
    "        #dists_nuc = self._pdist(rs, self.geom.coords[None, ...])\n",
    "        xs, (dists_nuc, dists_el) = self._featurize(rs)\n",
    "        ys = self.deep_lin(xs).squeeze(dim=1)\n",
    "        return self.nuc_asymp(dists_nuc) * torch.exp(ys) * self.antisym(rs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2p = geomdb['H2+']\n",
    "h2 = geomdb['H2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HF WF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = gto.M(\n",
    "    atom=[\n",
    "        ['H', (-0.742, 0, 0)],\n",
    "        ['H', (0.742, 0, 0)]\n",
    "    ],\n",
    "    unit='bohr',\n",
    "    basis='4-31G',\n",
    "    charge=0,\n",
    "    spin=2,\n",
    ")\n",
    "mf = scf.RHF(mol)\n",
    "mf.kernel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gtowf.get_aos(torch.randn(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtowf = TorchGTOSlaterWF(mf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_electrons=2\n",
    "molecule = h2\n",
    "\n",
    "Onet = Net().cuda()\n",
    "Pnet = Net_pair(molecule).cuda()\n",
    "net = WFNetAnti(molecule,n_electrons,Onet,Pnet,ion_pot=0.7).cuda()\n",
    "\n",
    "L = []\n",
    "V = []\n",
    "\n",
    "x_line = torch.cat((torch.linspace(-3, 3, 500)[:, None], torch.zeros((500, 3*n_electrons-1))), dim=1)\n",
    "x_line=x_line.view(-1,n_electrons,3).cuda()\n",
    "#mesh = get_3d_cube_mesh([(-6, 6), (-4, 4), (-4, 4)], [600, 400, 400])\n",
    "\n",
    "opt = torch.optim.Adam(net.parameters(), lr=1e-2)\n",
    "t_start=time.time()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=1, gamma=0.999)\n",
    "\n",
    "steps = 2000\n",
    "batchsize = 50_000\n",
    "n_resamplings = 100\n",
    "n_walker = 1_000\n",
    "\n",
    "sampler = langevin_monte_carlo(\n",
    "    gtowf,\n",
    "    torch.randn(n_walker, n_electrons, 3, device='cuda'),\n",
    "    tau=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "#temporary\n",
    "molecule._coords=molecule._coords.cuda()\n",
    "molecule._charges=molecule._charges.cuda()\n",
    "\n",
    "for i_step in range(steps):\n",
    "        \n",
    "    if i_step%(steps//4) == 0 or i_step==steps:\n",
    "        with torch.no_grad():\n",
    "            Psi2 = net(x_line)**2\n",
    "            plt.plot(x_line[:,0 , 0].cpu().detach().numpy(), Psi2.cpu().detach().numpy(),label=i_step)\n",
    "    \n",
    "    scheduler.step()\n",
    "    if i_step%(steps//n_resamplings)==0:\n",
    "        print(\"resample                                                                        \",end=\"\\r\")\n",
    "        rs,rs_psis  = samples_from(sampler,range(int(batchsize*steps/(n_resamplings*n_walker))))[0:-1]\n",
    "        rs = rs.flatten(end_dim=1).cuda()\n",
    "        rs_psis = rs_psis.flatten(end_dim=1).cuda()\n",
    "        idx = torch.randperm(len(rs))\n",
    "        rs = rs[idx]\n",
    "        rs_psis = rs_psis[idx]\n",
    "        \n",
    "    r=rs[i_step%(steps//n_resamplings)*batchsize:(i_step%(steps//n_resamplings)+1)*batchsize]\n",
    "    loss = torch.sum((net(r)**2-gtowf(r).cuda()**2)**2)\n",
    "    \n",
    "    print(\"Progress {:2.0%}\".format(i_step /steps)+\"   ->\"+\"I\"*(int(i_step/steps*100)//10)+\"i\"*(int(i_step/steps*100)%10)+\"  \"+\"current loss = \"+str(np.round(loss.item(),4))+\"        \", end=\"\\r\")\n",
    "\n",
    "\n",
    "    loss.backward()\n",
    "    L.append(loss.cpu().detach().numpy())\n",
    "    #V.append(((E_loc**2-E_loc.mean()**2).mean()).cpu().detach().numpy())\n",
    "    \n",
    "    torch.nn.utils.clip_grad_norm_(net.parameters(),1000)\n",
    "    \n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "plt.legend()\n",
    "print(\"it took =\"+str(np.round(time.time()-t_start,5))+\"                    \")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_line = torch.cat((torch.linspace(-5, 5, 5000)[:, None], torch.zeros((5000, 3*n_electrons-1))), dim=1)\n",
    "x_line=x_line.view(-1,n_electrons,3).cuda()\n",
    "x_line.requires_grad = True\n",
    "net.cuda()\n",
    "f_line = net._featurize(x_line)\n",
    "normed=True\n",
    "#normplot(x_line[:,0 , 0].cpu().detach().numpy(), torch.exp(net.deep_lin(f_line[0])).squeeze().cpu().detach().numpy(),label=\"sym\",norm=normed)\n",
    "#normplot(x_line[:,0 , 0].cpu().detach().numpy(), net.antisym(x_line).cpu().detach().numpy(),label=\"anti\",norm=normed)\n",
    "#normplot(x_line[:,0 , 0].cpu().detach().numpy(), net.nuc_asymp(f_line[1][0]).cpu().detach().numpy(),label=\"asym\",norm=normed)\n",
    "#N = net.nuc_asymp(f_line[1][0]).cpu().detach().numpy()\n",
    "#normplot(x_line[:,0,0].cpu().detach().numpy(),-1*(N*x_line[:,0,0].cpu().detach().numpy()),label=\"asym*line\",norm=normed)\n",
    "normplot(x_line[:,0 , 0].cpu().detach().numpy(), net(x_line).cpu().detach().numpy()**2,label=\"WF\",norm=normed,lw=2,color='k')\n",
    "normplot(x_line[:,0 , 0].cpu().detach().numpy(), gtowf(x_line.cpu().detach()).numpy()**2,label=\"gtowf\",norm=normed,lw=2,color='grey')\n",
    "\n",
    "plt.axhline(0,ls=':',color='k')\n",
    "plt.axvline(0,ls=':',color='k')\n",
    "\n",
    "#plt.ylim(-1,2)\n",
    "x_line.requires_grad = False\n",
    "plt.legend()\n",
    "plt.savefig('lastrunwf.png')\n",
    "plt.show()\n",
    "plt.subplot2grid((2,1),(0,0))\n",
    "plt.plot(L[:steps//10])\n",
    "plt.yscale('log')\n",
    "plt.subplot2grid((2,1),(1,0))\n",
    "plt.plot(L[steps//10:])\n",
    "plt.yscale('log')\n",
    "plt.savefig('lastrunloss.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "for i in range(6):\n",
    "    plt.subplot2grid((2,3),(i//3,i%3))\n",
    "    x = torch.zeros(500, 6)\n",
    "    x[:,0] = 0\n",
    "    x[:,i] = torch.linspace(-5, 5, 500)\n",
    "    x = x.view(-1,2,3)\n",
    "    plt.title(\"electron \" +str(i//3+1))\n",
    "    plt.plot(np.linspace(-5, 5, 500),gtowf(x).detach().numpy()**2)\n",
    "    plt.plot(np.linspace(-5, 5, 500),net(x).cpu().detach().numpy()**2)\n",
    "    plt.axhline(0,ls=':',color='k')\n",
    "    plt.savefig(\"supervised.png\")\n",
    "    #plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### try:\n",
    "    net.cuda()\n",
    "    plt.figure(figsize=(12,4))\n",
    "    for i in range(6):\n",
    "        plt.subplot2grid((2,3),(i//3,i%3))\n",
    "        x = torch.zeros(500, 6)\n",
    "        x[:,i] = torch.linspace(-5, 5, 500)\n",
    "        x = x.view(-1,2,3)\n",
    "        plt.title(\"electron \" +str(i//3+1))\n",
    "        plt.plot(np.linspace(-5, 5, 500),net(x.cuda()).cpu().detach().numpy()**2)\n",
    "        plt.axhline(0,ls=':',color='k')\n",
    "        #plt.axis('off')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    G = np.array(np.meshgrid(np.linspace(-5, 5, 500),np.linspace(-5, 5, 500))).T.reshape(-1,2)\n",
    "    F = np.append(G,np.ones((250000,4)),axis=-1)\n",
    "    H = np.append(F[:,[0,2,4]],F[:,[1,3,5]],axis=-1)\n",
    "    W1 = gtowf(torch.from_numpy(H).view(-1,2,3)).view(500,500).numpy()\n",
    "    W2 = net(torch.from_numpy(H).view(-1,2,3).type(torch.FloatTensor).cuda()).view(500,500).cpu().detach().numpy()\n",
    "    levels=30\n",
    "    plt.figure(figsize=(8,3))\n",
    "    plt.subplot2grid((1,2),(0,0))\n",
    "    plt.title(\"gtowf\")\n",
    "    plt.contourf(W1,levels)\n",
    "    plt.colorbar()\n",
    "    plt.subplot2grid((1,2),(0,1))\n",
    "    plt.title(\"netwf\")\n",
    "    plt.contourf(W2,levels)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_electrons=2\n",
    "n_up = 2\n",
    "n_down = n_electrons-n_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = HanNet(h2,n_up,n_down).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    sampler = hmc(\n",
    "        net,\n",
    "        torch.randn(1000, n_electrons, 3, device='cuda'),\n",
    "        dysteps=3,\n",
    "        stepsize=0.2,\n",
    "        tau = 0.1,\n",
    "        cutoff = 1.0\n",
    "    )\n",
    "else:\n",
    "    sampler = langevin_monte_carlo(\n",
    "        net,\n",
    "        torch.randn(1000, n_electrons, 3, device='cuda'),\n",
    "        tau=0.1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t=time.time()\n",
    "#samples = samples_from(sampler,range(1000))[0].flatten(end_dim=1)\n",
    "#print(\"it took: \"+str(time.time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecule = h2\n",
    "fit_wfnet(\n",
    "    net,\n",
    "    partial(loss_local_energy, E_ref=-1.1,p=2),\n",
    "    torch.optim.Adam(net.parameters(), lr=1e-3),\n",
    "    wfnet_fit_driver(\n",
    "            sampler,\n",
    "            samplings=range(1),\n",
    "            n_epochs=1,\n",
    "            n_sampling_steps=250,\n",
    "            batch_size=1_000,\n",
    "            n_discard=50,\n",
    "            range_sampling=partial(trange, desc='sampling steps', leave=False),\n",
    "            range_training=partial(trange, desc='training steps', leave=False),\n",
    "        ),\n",
    "        writer = SummaryWriter(f'runs/'),\n",
    "    )\n",
    "fit_wfnet(\n",
    "    net,\n",
    "    partial(loss_local_energy, E_ref=None,p=1),\n",
    "    torch.optim.Adam(net.parameters(), lr=1e-3),\n",
    "    wfnet_fit_driver(\n",
    "            sampler,\n",
    "            samplings=range(1),\n",
    "            n_epochs=3,\n",
    "            n_sampling_steps=850,\n",
    "            batch_size=1_000,\n",
    "            n_discard=50,\n",
    "            range_sampling=partial(trange, desc='sampling steps', leave=False),\n",
    "            range_training=partial(trange, desc='training steps', leave=False),\n",
    "        ),\n",
    "    clip_grad = 0.1,\n",
    "    writer = SummaryWriter(f'runs/'),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_line = torch.cat((torch.linspace(-5, 5, 5000)[:, None], torch.zeros((5000, 3*n_electrons-1))), dim=1)\n",
    "x_line[:,3]=h2.coords[1][0]/2\n",
    "x_line=x_line.view(-1,n_electrons,3).cuda()\n",
    "x_line.requires_grad = True\n",
    "net.cuda()\n",
    "#f_line = net._featurize(x_line)\n",
    "normed=True\n",
    "#normplot(x_line[:,0 , 0].cpu().detach().numpy(), torch.exp(net.deep_lin(f_line[0])).squeeze().cpu().detach().numpy(),label=\"sym\",norm=normed)\n",
    "#normplot(x_line[:,0 , 0].cpu().detach().numpy(), net.antisym(x_line).cpu().detach().numpy(),label=\"anti\",norm=normed)\n",
    "#normplot(x_line[:,0 , 0].cpu().detach().numpy(), net.nuc_asymp(f_line[1][0]).cpu().detach().numpy(),label=\"asym\",norm=normed)\n",
    "#N = net.nuc_asymp(f_line[1][0]).cpu().detach().numpy()\n",
    "#normplot(x_line[:,0,0].cpu().detach().numpy(),-1*(N*x_line[:,0,0].cpu().detach().numpy()),label=\"asym*line\",norm=normed)\n",
    "d=net(x_line).cpu().detach().numpy()\n",
    "D.append(d)\n",
    "normplot(x_line[:,0 , 0].cpu().detach().numpy(), net(x_line).cpu().detach().numpy(),label=\"WF\",norm=normed,lw=2,color='k')\n",
    "\n",
    "plt.axhline(0,ls=':',color='k')\n",
    "plt.axvline(0,ls=':',color='k')\n",
    "\n",
    "#plt.ylim(-1,2)\n",
    "x_line.requires_grad = False\n",
    "plt.legend()\n",
    "#plt.savefig('lastrunwf.png')\n",
    "plt.show()\n",
    "#plt.subplot2grid((2,1),(0,0))\n",
    "#plt.plot(L[:steps//10])\n",
    "#plt.yscale('log')\n",
    "#plt.subplot2grid((2,1),(1,0))\n",
    "#plt.plot(L[steps//10:])\n",
    "#plt.yscale('log')\n",
    "#plt.savefig('lastrunloss.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in D:\n",
    "    plt.plot(d)\n",
    "    #plt.savefig('hmm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(x_line[:,0 , 0].cpu().detach().numpy(),net.antisym.net_pair_anti(x_line[:,0],x_line[:,1]).cpu().detach().numpy())\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp = net.antisym.net_pair_anti(torch.from_numpy(H[:,0:3]).type(torch.FloatTensor).cuda(),torch.from_numpy(H[:,3:]).type(torch.FloatTensor).cuda()).cpu().detach().numpy()[:,9].reshape(500,500)\n",
    "#plt.contourf(tmp)\n",
    "#plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=time.time()\n",
    "samples = samples_from(sampler,range(100))[0].flatten(end_dim=1)\n",
    "print(\"it took: \"+str(time.time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(\n",
    "    samples[:,0, 0].cpu().detach().numpy(),\n",
    "    samples[:,0, 1].cpu().detach().numpy(),\n",
    "    bins=100,\n",
    "    range=[[-3, 3], [-3, 3]],\n",
    ")                                   \n",
    "plt.gca().set_aspect(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = net.cpu()\n",
    "#samples = samples.cpu()\n",
    "h2._coords  = h2._coords.cuda()\n",
    "h2._charges = h2._charges.cuda()\n",
    "h2.coords.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_loc = dlqmc.utils.batch_eval_tuple(partial(local_energy, wf=lambda x: net(x),geom=h2),1000,samples.view([-1,n_electrons,3]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.where((E_loc.detach().numpy())>100)[0].shape)\n",
    "#print(np.where((E_loc.detach().numpy())<-100)[0].shape)\n",
    "#print(np.min(E_loc.detach().numpy()))\n",
    "#print(np.max(E_loc.detach().numpy()))\n",
    "#net(samples[np.where((E_loc.detach().numpy())>10)])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=E_loc.clamp(-10, 10).mean().item()\n",
    "\n",
    "h = plt.hist(E_loc.detach().clamp(-1.5, 1).cpu().numpy(), bins=100,alpha = 0.5,color='b')\n",
    "plt.annotate(\"mean = \"+str(np.round(mean,4)),(-0.3,np.max(h[0])/2),color='b')\n",
    "plt.annotate(\"var     = \"+str(np.round(np.var(E_loc.detach().clamp(-10, 10).cpu().numpy()),4)),(-0.3,np.max(h[0])/2-np.max(h[0])/15),color='b')\n",
    "\n",
    "#mean=e_loc_net.mean()\n",
    "\n",
    "#h = plt.hist(e_loc_net, bins=100,color='r',alpha = 0.5)\n",
    "#plt.annotate(\"mean = \"+str(np.round(mean,4)),(0,np.max(h[0])/2-3000),color='r')\n",
    "#plt.annotate(\"var     = \"+str(np.round(np.var(e_loc_net),4)),(0,np.max(h[0])/2-np.max(h[0])/15-3000),color='r')\n",
    "plt.savefig('lastruneloc.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e_loc_net=E_loc.detach().clamp(-1.5, 1).cpu().numpy().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_allocated()\n",
    "torch.cuda.memory_cached(device=None)\n",
    "torch.cuda.max_memory_cached(device=None)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-qmc",
   "language": "python",
   "name": "dl-qmc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
